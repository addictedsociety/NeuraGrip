{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#            _____  _____ _____ _____ _______ ______ _____   _____  ____   _____ _____ ______ _________     __\n",
    "#      /\\   |  __ \\|  __ \\_   _/ ____|__   __|  ____|  __ \\ / ____|/ __ \\ / ____|_   _|  ____|__   __\\ \\   / /\n",
    "#     /  \\  | |  | | |  | || || |       | |  | |__  | |  | | (___ | |  | | |      | | | |__     | |   \\ \\_/ / \n",
    "#    / /\\ \\ | |  | | |  | || || |       | |  |  __| | |  | |\\___ \\| |  | | |      | | |  __|    | |    \\   /  \n",
    "#   / ____ \\| |__| | |__| || || |____   | |  | |____| |__| |____) | |__| | |____ _| |_| |____   | |     | |   \n",
    "#  /_/    \\_\\_____/|_____/_____\\_____|  |_|  |______|_____/|_____/ \\____/ \\_____|_____|______|  |_|     |_|  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Einführung in die Gesichtserkennung mit OpenCV**\n",
    "\n",
    "In dieser Lerneinheit wirst du lernen, wie man mit OpenCV eine einfache Gesichtserkennung implementiert. OpenCV ist eine mächtige Bibliothek für Computer Vision, die eine Vielzahl von vortrainierten Modellen und Funktionen bietet, um Aufgaben wie Gesichtserkennung, Objekterkennung und vieles mehr zu bewältigen.\n",
    "\n",
    "OpenCV steht für \"Open Source Computer Vision\". Es handelt sich um eine weit verbreitete Open-Source-Bibliothek, die sowohl für akademische als auch industrielle Anwendungen genutzt wird, um Bild- und Videoverarbeitungsprojekte zu realisieren.\n",
    "\n",
    "Wenn du an weiteren spannenden Themen rund um Computer Vision, KI und Programmierung interessiert bist, abonniere gerne meinen YouTube-Kanal [@addicted_society](https://www.youtube.com/@addicted_society), um keine neuen Videos zu verpassen!\n",
    "\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation von OpenCV und weiteren relevanten Bibliotheken\n",
    "\n",
    "Um mit der Gesichtserkennung und Objekterkennung loszulegen, müssen wir OpenCV und einige andere relevante Bibliotheken installieren.\n",
    "\n",
    "### 1. Installation von OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\envs\\addictedsocietyenv\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\anaconda3\\envs\\addictedsocietyenv\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Installation weiterer Bibliotheken\n",
    "\n",
    "Neben OpenCV benötigen wir zusätzliche Bibliotheken, um fortschrittliche Modelle wie YOLO verwenden zu können:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unterschiede zwischen YOLO, MediaPipe und OpenCV\n",
    "\n",
    "- **OpenCV**:\n",
    "  - **Art**: Bibliothek für Bildverarbeitung und Computer Vision.\n",
    "  - **Anwendung**: Bildbearbeitung, Filter, Bewegungserkennung, Unterstützung von ML-Modellen (z.B. YOLO).\n",
    "  - **Vorteile**: Vielseitigkeit, große Funktionalität.\n",
    "  - **Nachteile**: Weniger spezialisiert auf neuronale Netze, langsamer bei komplexen Aufgaben.\n",
    "\n",
    "- **YOLO (You Only Look Once)**:\n",
    "  - **Art**: Objekterkennungs-Algorithmus (neuronales Netz).\n",
    "  - **Anwendung**: Echtzeit-Objekterkennung (z.B. Personen, Fahrzeuge).\n",
    "  - **Vorteile**: Schnell, erkennt mehrere Objekte gleichzeitig.\n",
    "  - **Nachteile**: Kann bei kleinen Objekten ungenauer sein.\n",
    "\n",
    "- **MediaPipe**:\n",
    "  - **Art**: Framework für ML-basierte Echtzeit-Tracking-Pipelines.\n",
    "  - **Anwendung**: Handverfolgung, Gesichtserkennung, Pose-Tracking.\n",
    "  - **Vorteile**: Einfach zu implementieren, effizient, vortrainierte Modelle.\n",
    "  - **Nachteile**: Eingeschränkte Anpassbarkeit für benutzerdefinierte Aufgaben.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "# **1. Basics von OpenCV**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesen eines Bildes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Bild lesen\n",
    "image = cv2.imread(r'Dateien\\Grafiken\\image.jpg') # hier den Pfad zum Bild eintragen\n",
    "\n",
    "# Bild anzeigen\n",
    "cv2.imshow('Gelesenes Bild', image)\n",
    "cv2.waitKey(0) # 0 bedeutet, dass das Bild so lange angezeigt wird, bis eine Taste gedrückt wird\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Größenänderung eines Bildes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Bild lesen\n",
    "image = cv2.imread(r'Dateien\\Grafiken\\image.jpg')\n",
    "\n",
    "# Bildgröße ändern\n",
    "resized_image = cv2.resize(image, (300, 300)) # x, y Skalierung\n",
    "\n",
    "# Bild anzeigen\n",
    "cv2.imshow('Größenänderung', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation eines Bildes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Bild lesen\n",
    "image = cv2.imread(r'Dateien\\Grafiken\\image.jpg')\n",
    "\n",
    "# Dimensionen des Bildes erhalten\n",
    "rows, cols = image.shape[:2] # Höhe, Breite\n",
    "\n",
    "# Rotationsmatrix erstellen\n",
    "rotation_matrix = cv2.getRotationMatrix2D((cols/2, rows/2), 45, 0.5) # Referenzpunkt, Winkel, Skalierung\n",
    "\n",
    "# Bild rotieren\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (cols, rows))\n",
    "rotated_image = cv2.resize(rotated_image, (300, 300))   \n",
    "# Bild anzeigen\n",
    "cv2.imshow('Rotation', rotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affine Transformation\n",
    "\n",
    "Affine Transformationen sind geometrische Operationen, die verwendet werden, um ein Bild zu verschieben, zu drehen, zu skalieren oder zu verzerren, während **gerade Linien und parallele Linien erhalten bleiben**. Es wird oft in der Bildverarbeitung und Computergrafik genutzt, z.B. zur geometrischen Anpassung.\n",
    "\n",
    "### Anwendungsfälle:\n",
    "- **Bildausrichtung:** Anpassung eines Bildes, um Objekte in eine bestimmte Position zu bringen.\n",
    "- **Augmentierung:** Variationen eines Bildes erstellen (z.B. für Machine Learning).\n",
    "- **Bildkorrekturen:** Schiefe Bilder begradigen oder perspektivische Verzerrungen beheben.\n",
    "- **Geometrische Transformationen:** Verschieben, Drehen, Skalieren oder Scheren von Bildern ohne Verformung der Strukturen.\n",
    "\n",
    "Affine Transformationen sind besonders nützlich, weil sie flexibel sind und grundlegende Veränderungen im Bild vornehmen können, ohne die Gesamtstruktur (z.B. Geraden und Verhältnisse) zu zerstören.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV-Bibliothek importieren, um Bildverarbeitung durchzuführen\n",
    "import numpy as np  # NumPy-Bibliothek importieren, um mit Matrizen und Arrays zu arbeiten\n",
    "\n",
    "# Bild einlesen von der angegebenen Dateipfad\n",
    "image = cv2.imread(r'Dateien\\Grafiken\\image.jpg')\n",
    "\n",
    "# Definieren von drei Punkten auf dem Originalbild, die für die Transformation verwendet werden (Quellpunkte)\n",
    "pts1 = np.float32([[50, 50], [200, 50], [50, 200]])\n",
    "\n",
    "# Definieren der drei Zielpunkte, wohin die Quellpunkte transformiert werden sollen (Zielpunkte)\n",
    "pts2 = np.float32([[10, 100], [200, 50], [100, 250]])\n",
    "\n",
    "# Berechnung der Affinen Transformationsmatrix basierend auf den Quell- und Zielpunkten\n",
    "affine_matrix = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "# Anwenden der affinen Transformation auf das Bild\n",
    "# Dabei wird das Bild um die neue Matrix verzerrt, verschoben oder gedreht\n",
    "transformed_image = cv2.warpAffine(image, affine_matrix, (image.shape[1], image.shape[0])) # Bild , Matrix, Größe\n",
    "\n",
    "# Das transformierte Bild auf eine Größe von 300x300 Pixeln skalieren\n",
    "transformed_image = cv2.resize(transformed_image, (300, 300))\n",
    "\n",
    "# Das transformierte Bild in einem Fenster anzeigen\n",
    "cv2.imshow('Affine Transformation', transformed_image)\n",
    "\n",
    "# Auf eine beliebige Taste warten, um das Fenster zu schließen\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeichnen von Formen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Leeres Bild erstellen\n",
    "image = cv2.imread(r'Dateien\\Grafiken\\image.jpg')\n",
    "\n",
    "# Linie zeichnen\n",
    "cv2.line(image, (0, 0), (250, 250), (255, 0, 0), 5) # Startpunkt, Endpunkt, Farbe(BGR), Dicke\n",
    "\n",
    "# Rechteck zeichnen\n",
    "cv2.rectangle(image, (10, 10), (200, 200), (0, 255, 0), -1) # Startpunkt, Endpunkt, Farbe(BGR), Dicke\n",
    "\n",
    "# Kreis zeichnen\n",
    "cv2.circle(image, (150, 150), 50, (0, 0, 255), -1) # Mittelpunkt, Radius, Farbe, Füllung (-1) = gefüllt\n",
    "\n",
    "\n",
    "\n",
    "image = cv2.resize(image, (500, 500))\n",
    "\n",
    "# Bild anzeigen\n",
    "cv2.imshow('Formen', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text hinzufügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Bild lesen\n",
    "image = cv2.imread(r'Dateien\\Grafiken\\image.jpg')\n",
    "\n",
    "# Text hinzufügen\n",
    "cv2.putText(image, 'Hello OpenCV!', (50, 500), cv2.FONT_HERSHEY_SIMPLEX, 10, (255, 255, 255), 50) # Text, Position, Schriftart, Skalierung, Farbe, Dicke\n",
    "image = cv2.resize(image, (500, 500))\n",
    "# Bild anzeigen\n",
    "cv2.imshow('Text', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Essentielle Funktionen in OpenCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Farbumwandlung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Bild von der angegebenen Datei lesen\n",
    "image = cv2.imread(r'Dateien\\Grafiken\\image.jpg')\n",
    "\n",
    "# Umwandlung des Farb-Bildes in ein Graustufen-Bild\n",
    "# cvtColor konvertiert das Bild von BGR (Blau, Grün, Rot) in Grau\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Das Graustufen-Bild auf 500x500 Pixel skalieren\n",
    "gray_image = cv2.resize(gray_image, (500, 500))\n",
    "\n",
    "# Das Graustufen-Bild in einem Fenster anzeigen\n",
    "cv2.imshow('Graustufen', gray_image)\n",
    "\n",
    "# Auf eine beliebige Taste warten, um das Fenster zu schließen\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Bildglättung (Gaussian Blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Gaussian Blur (Weichzeichnung) auf das Bild anwenden\n",
    "# (5, 5) ist die Kernelgröße, und 5 ist die Standardabweichung für den Filter\n",
    "blurred_image = cv2.GaussianBlur(image, (7, 7), 5)\n",
    "\n",
    "# Das weichgezeichnete Bild auf 500x500 Pixel skalieren\n",
    "blurred_image = cv2.resize(blurred_image, (500, 500))\n",
    "\n",
    "# Das Originalbild ebenfalls auf 500x500 Pixel skalieren, um beide Bilder gleich groß anzuzeigen\n",
    "original_resized = cv2.resize(image, (500, 500))\n",
    "\n",
    "# Das weichgezeichnete Bild in einem Fenster anzeigen\n",
    "cv2.imshow('Gaussian Blur', blurred_image)\n",
    "\n",
    "# Das Originalbild in einem separaten Fenster anzeigen\n",
    "cv2.imshow('Original', original_resized)\n",
    "\n",
    "# Auf eine beliebige Taste warten, um beide Fenster zu schließen\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Kanten erkennen (Canny Edge Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Bild lesen\n",
    "image = cv2.imread(r'Dateien\\Grafiken\\image.jpg')\n",
    "\n",
    "# Canny Edge Detection anwenden\n",
    "# 100 und 200 sind die unteren und oberen Schwellenwerte für die Kantenerkennung\n",
    "edges = cv2.Canny(image, 100, 150)\n",
    "\n",
    "# Das Kantenbild auf 500x500 Pixel skalieren\n",
    "edges = cv2.resize(edges, (500, 500))\n",
    "\n",
    "# Das Kantenbild in einem Fenster anzeigen\n",
    "cv2.imshow('Kanten', edges)\n",
    "\n",
    "# Auf eine beliebige Taste warten, um das Fenster zu schließen\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Bild zuschneiden (Cropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Bild von der angegebenen Datei lesen\n",
    "image = cv2.imread(r'Dateien\\Grafiken\\image.jpg')\n",
    "\n",
    "# Bild zuschneiden: Das Bild wird von Zeile 50 bis 200 und Spalte 100 bis 300 ausgeschnitten\n",
    "# Die Syntax ist image[Höhe (y):Höhe (y), Breite (x):Breite (x)]\n",
    "cropped_image = image[50:200, 100:300]\n",
    "\n",
    "# Das zugeschnittene Bild in einem Fenster anzeigen\n",
    "cv2.imshow('Zuschneiden', cropped_image)\n",
    "\n",
    "# Auf eine beliebige Taste warten, um das Fenster zu schließen\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Bild Graustufen und Binarisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Bild von der angegebenen Datei lesen\n",
    "image = cv2.imread(r'Dateien\\Grafiken\\image.jpg')\n",
    "\n",
    "# Umwandlung des Farb-Bildes in ein Graustufen-Bild\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Bild binarisieren: Alle Pixelwerte unter 127 werden auf 0 (Schwarz) gesetzt,\n",
    "# alle Pixelwerte über 127 werden auf 255 (Weiß) gesetzt\n",
    "_, binary_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "# _, hierbei handelt es sich um den Rückgabewert von threshold, den wir nicht benötigen\n",
    "\n",
    "original_resized = cv2.resize(image, (500, 500))\n",
    "\n",
    "# Das binarisierte Bild auf 500x500 Pixel skalieren\n",
    "binary_image = cv2.resize(binary_image, (500, 500))\n",
    "\n",
    "# Das binarisierte Bild in einem Fenster anzeigen\n",
    "cv2.imshow('Binarisieren', binary_image)\n",
    "cv2.imshow('Original', original_resized)\n",
    "\n",
    "# Auf eine beliebige Taste warten, um das Fenster zu schließen\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warum diese 5 Funktionen in OpenCV essenziell sind\n",
    "\n",
    "1. **Farbumwandlung (Color Conversion)**:\n",
    "   - **Vereinfachung der Analyse**: Reduziert die Bildkomplexität, indem Farbbilder in Graustufenbilder umgewandelt werden, was für viele Bildverarbeitungsalgorithmen unerlässlich ist.\n",
    "\n",
    "2. **Bildglättung (Gaussian Blur)**:\n",
    "   - **Rauschreduzierung**: Entfernt Bildrauschen und glättet Details, was die Genauigkeit nachfolgender Verarbeitungsschritte wie Kantenerkennung verbessert.\n",
    "\n",
    "3. **Kanten erkennen (Canny Edge Detection)**:\n",
    "   - **Struktur- und Konturenerkennung**: Ermöglicht die Identifikation von signifikanten Bildstrukturen und Konturen, die für die Objekterkennung und Segmentierung notwendig sind.\n",
    "\n",
    "4. **Bild zuschneiden (Cropping)**:\n",
    "   - **Fokussierung auf relevante Bereiche**: Erlaubt es, sich auf wichtige Teile des Bildes zu konzentrieren, was die Effizienz und Präzision der Analyse steigert.\n",
    "\n",
    "5. **Bild binarisieren (Thresholding)**:\n",
    "   - **Hervorhebung von Merkmalen**: Wandelt Graustufenbilder in binäre Bilder um, wodurch wichtige Merkmale wie Kanten besser hervorgehoben werden und die Verarbeitung vereinfacht wird.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesen eines Videos oder Webcam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Video öffnen (entweder von einer Datei oder eine Webcam, z. B. 0 für die Standard-Webcam)\n",
    "video = cv2.VideoCapture(r'Dateien\\Grafiken\\video.mp4')  # Den Pfad zum Video angeben oder 0 für Webcam verwenden\n",
    "\n",
    "# Schleife, solange das Video geöffnet ist\n",
    "while video.isOpened():\n",
    "    # Frame aus dem Video lesen\n",
    "    ret, frame = video.read()  # ret ist True, wenn das Frame erfolgreich gelesen wurde, frame enthält das gelesene Bild\n",
    "    if not ret:  # Wenn kein Frame mehr gelesen werden kann (Ende des Videos)\n",
    "        break\n",
    "    \n",
    "    # Frame skalieren: Hier wird die Größe um den Faktor 0.25 reduziert (25% der ursprünglichen Größe)\n",
    "    resize_p = 0.25\n",
    "    frame = cv2.resize(frame, (int(frame.shape[1]*resize_p), int(frame.shape[0]*resize_p)))  # Breite und Höhe des Frames entsprechend anpassen\n",
    "    \n",
    "    # Das aktuelle Frame in einem Fenster anzeigen\n",
    "    cv2.imshow('Video Frame', frame)\n",
    "    \n",
    "    # Wenn die Taste 'q' gedrückt wird, die Schleife beenden und das Video stoppen\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigeben des VideoCapture-Objekts\n",
    "video.release()\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV-Bibliothek importieren\n",
    "\n",
    "# Videoquelle öffnen (0 für die Standard-Webcam)\n",
    "video = cv2.VideoCapture(0)  # 0 bedeutet, dass die Webcam verwendet wird\n",
    "\n",
    "# Schleife, solange das Video geöffnet ist\n",
    "while video.isOpened():\n",
    "    # Frame von der Webcam lesen\n",
    "    ret, frame = video.read()  # ret ist True, wenn ein Frame erfolgreich gelesen wurde, frame enthält das aktuelle Bild\n",
    "    if not ret:  # Falls kein Frame gelesen werden konnte (z. B. bei einem Fehler oder Ende des Videos)\n",
    "        break\n",
    "\n",
    "    # Frame skalieren: Hier wird die Größe des Frames verdoppelt (Skalierungsfaktor 2)\n",
    "    resize_p = 2\n",
    "    frame = cv2.resize(frame, (int(frame.shape[1]*resize_p), int(frame.shape[0]*resize_p)))  # Breite und Höhe des Frames anpassen\n",
    "    \n",
    "    # Das aktuelle Frame in einem Fenster anzeigen\n",
    "    cv2.imshow('Camera Frame', frame)  # Den Live-Feed der Webcam anzeigen\n",
    "    \n",
    "    # Wenn die Taste 'q' gedrückt wird, beende die Schleife und stoppe die Videoanzeige\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigeben der Videoquelle (Webcam)\n",
    "video.release()\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "---\n",
    "# **2. Erweiterte Konzepte**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Farbräume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV-Bibliothek importieren\n",
    "\n",
    "# Webcam starten (0 bedeutet Standard-Webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Schleife, die Frames von der Webcam kontinuierlich liest\n",
    "while True:\n",
    "    ret, frame = cap.read()  # ret gibt an, ob das Frame erfolgreich gelesen wurde, frame enthält das aktuelle Bild\n",
    "    if not ret:  # Wenn kein Frame gelesen werden kann, beende die Schleife\n",
    "        break\n",
    "\n",
    "    # Umwandlung des Frames in verschiedene Farbräume\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Konvertierung in Graustufen\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)    # Konvertierung in den HSV-Farbraum (Hue, Saturation, Value)\n",
    "    lab_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)    # Konvertierung in den LAB-Farbraum\n",
    "\n",
    "    # Anzeige der Original- und konvertierten Frames in separaten Fenstern\n",
    "    cv2.imshow('Original Frame', frame)      # Originalbild anzeigen\n",
    "    cv2.imshow('Gray Frame', gray_frame)     # Graustufenbild anzeigen\n",
    "    cv2.imshow('HSV Frame', hsv_frame)       # HSV-Bild anzeigen\n",
    "    cv2.imshow('LAB Frame', lab_frame)       # LAB-Bild anzeigen\n",
    "    \n",
    "    # Beenden, wenn die Taste 'q' gedrückt wird\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigeben der Webcam-Ressourcen\n",
    "cap.release()\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Farbkanäle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV-Bibliothek importieren\n",
    "\n",
    "# Webcam starten (0 bedeutet Standard-Webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Schleife, die Frames von der Webcam kontinuierlich liest\n",
    "while True:\n",
    "    ret, frame = cap.read()  # ret gibt an, ob das Frame erfolgreich gelesen wurde, frame enthält das aktuelle Bild\n",
    "    if not ret:  # Wenn kein Frame gelesen werden kann, beende die Schleife\n",
    "        break\n",
    "\n",
    "    # Aufteilen des Frames in die drei Farbkanäle B (Blau), G (Grün), R (Rot)\n",
    "    B, G, R = cv2.split(frame)\n",
    "\n",
    "\n",
    "    # Erstellen von Bildern, die jeweils nur einen der Farbkanäle anzeigen\n",
    "    blue_frame = cv2.merge([B, B*0, B*0])   # Bild, das nur den blauen Kanal enthält\n",
    "    green_frame = cv2.merge([G*0, G, G*0])  # Bild, das nur den grünen Kanal enthält\n",
    "    red_frame = cv2.merge([R*0, R*0, R])    # Bild, das nur den roten Kanal enthält\n",
    "\n",
    "    # Anzeige der einzelnen Farbkanäle in separaten Fenstern\n",
    "    cv2.imshow('Blue Channel', blue_frame)   # Nur Blau anzeigen\n",
    "    cv2.imshow('Green Channel', green_frame) # Nur Grün anzeigen\n",
    "    cv2.imshow('Red Channel', red_frame)     # Nur Rot anzeigen\n",
    "    \n",
    "    # Beenden, wenn die Taste 'q' gedrückt wird\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigeben der Webcam-Ressourcen\n",
    "cap.release()\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Weichzeichnen (Blurring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV-Bibliothek importieren\n",
    "\n",
    "# Webcam starten (0 bedeutet Standard-Webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Schleife, die Frames von der Webcam kontinuierlich liest\n",
    "while True:\n",
    "    ret, frame = cap.read()  # ret gibt an, ob das Frame erfolgreich gelesen wurde, frame enthält das aktuelle Bild\n",
    "    if not ret:  # Wenn kein Frame gelesen werden kann, beende die Schleife\n",
    "        break\n",
    "\n",
    "    # Verschiedene Weichzeichnungs-Methoden\n",
    "    blurred = cv2.blur(frame, (5, 5))  # Durchschnittsfilter mit einem 5x5 Kernel (Box-Filter)\n",
    "    gaussian_blurred = cv2.GaussianBlur(frame, (5, 5), 0)  # Gauss'scher Weichzeichner mit einem 5x5 Kernel, 0 bedeutet, dass die Standardabweichung automatisch berechnet wird\n",
    "    median_blurred = cv2.medianBlur(frame, 5)  # Medianfilter mit einem Kernel von 5x5\n",
    "\n",
    "    # Anzeigen der Frames mit den jeweiligen Weichzeichnungs-Methoden\n",
    "    cv2.imshow('Blurred Frame', blurred)  # Frame mit Durchschnittsfilter\n",
    "    cv2.imshow('Gaussian Blurred Frame', gaussian_blurred)  # Frame mit Gauss'schem Weichzeichner\n",
    "    cv2.imshow('Median Blurred Frame', median_blurred)  # Frame mit Medianfilter\n",
    "    \n",
    "    # Beenden, wenn die Taste 'q' gedrückt wird\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigeben der Webcam-Ressourcen\n",
    "cap.release()\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Bitweise Operationen Maskieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape[0]: Höhe des Bildes (Anzahl der Zeilen).\n",
    "# shape[1]: Breite des Bildes (Anzahl der Spalten).\n",
    "# shape[2]: Anzahl der Farbkanäle (meist 3 für BGR).\n",
    "# frame.shape[:2] bedeutet, dass nur die ersten zwei Werte, also Höhe und Breite, verwendet werden, um ein zweidimensionales Array zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Webcam starten\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Webcam-Bild (Frame) einlesen\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Maske erstellen: Ein schwarzes Bild (gleiche Größe wie das Frame)\n",
    "    mask = np.zeros(frame.shape[:2], dtype=\"uint8\")  # 'zeros' erstellt ein Bild nur mit Schwarz (0), dtype bestimmt den Datentyp (uint8 für 8-Bit Werte)\n",
    "    \n",
    "    # Rechteck in die Maske zeichnen: Ein weißes Rechteck von (50, 50) bis (250, 250)\n",
    "    cv2.rectangle(mask, (50, 50), (250, 250), 255, -1)  # '-1' füllt das Rechteck mit der Farbe 255 (Weiß)\n",
    "    \n",
    "    # Kreis in die Maske zeichnen: Ein weißer Kreis in der Mitte des Bildes mit Radius 150\n",
    "    cv2.circle(mask, (frame.shape[1]//2, frame.shape[0]//2), 150, 255, -1)  # Mittelpunkt ist der Bildmittelpunkt\n",
    "\n",
    "    # Bitweise Operationen:\n",
    "    # AND: Nur die Pixel behalten, die in beiden Bildern (Frame und Maske) weiß sind\n",
    "    bitwise_and = cv2.bitwise_and(frame, frame, mask=mask) \n",
    "    \n",
    "    # OR: Pixel behalten, die in einem der beiden Bilder (Frame oder Maske) weiß sind\n",
    "    bitwise_or = cv2.bitwise_or(frame, frame, mask=mask)\n",
    "    \n",
    "    # XOR: Nur die Pixel behalten, die entweder im Frame oder der Maske weiß sind, aber nicht in beiden\n",
    "    bitwise_xor = cv2.bitwise_xor(frame, frame, mask=mask)\n",
    "    \n",
    "    # NOT: Negation der Maske (Schwarz wird zu Weiß, Weiß zu Schwarz)\n",
    "    bitwise_not = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Ergebnisse der Operationen anzeigen\n",
    "    cv2.imshow('AND', bitwise_and)\n",
    "    cv2.imshow('OR', bitwise_or)\n",
    "    cv2.imshow('XOR', bitwise_xor)\n",
    "    cv2.imshow('NOT', bitwise_not)\n",
    "    \n",
    "    # Beenden, wenn 'q' gedrückt wird\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigabe der Webcam-Ressourcen und Schließen der Fenster\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Histogrammberechnung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bild lesen\n",
    "image = cv2.imread(r'Dateien\\Grafiken\\image.jpg')  # Pfad zum Bild eintragen\n",
    "# Mit 'cv2.imread()' wird das Bild von der Festplatte gelesen und in eine Matrix (NumPy-Array) umgewandelt,\n",
    "# die die Pixelwerte des Bildes enthält. In diesem Fall wird ein Bild im BGR-Format geladen.\n",
    "\n",
    "# Umwandlung in Graustufen\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Das geladene Farbbild wird mit 'cv2.cvtColor()' in ein Graustufenbild umgewandelt. Dies reduziert die \n",
    "# Farbkanäle von 3 (BGR) auf 1 (Graustufen), da das Histogramm für ein Graustufenbild erstellt wird.\n",
    "\n",
    "# Histogramm berechnen\n",
    "histogram = cv2.calcHist([gray_image], [0], None, [256], [0, 256])\n",
    "# 'cv2.calcHist()' berechnet das Histogramm des Graustufenbildes. Die Parameter sind:\n",
    "# - [gray_image]: Die Eingabe, das Graustufenbild.\n",
    "# - [0]: Der Index des Kanals, für den das Histogramm berechnet wird (Graustufen hat nur 1 Kanal).\n",
    "# - None: Keine Maske, das Histogramm wird über das gesamte Bild berechnet.\n",
    "# - [256]: Anzahl der Bins (Intervalle für die Helligkeitswerte, von 0 bis 255).\n",
    "# - [0, 256]: Der Bereich der Helligkeitswerte, von 0 (schwarz) bis 255 (weiß).\n",
    "\n",
    "# Histogramm anzeigen\n",
    "plt.figure()\n",
    "plt.title(\"Grayscale Histogram\")\n",
    "plt.xlabel(\"Bins\")  # Die x-Achse repräsentiert die Helligkeitswerte (0 bis 255).\n",
    "plt.ylabel(\"# of Pixels\")  # Die y-Achse repräsentiert die Anzahl der Pixel in jedem Helligkeitsbereich.\n",
    "plt.plot(histogram)  # Das Histogramm wird geplottet, mit Helligkeitswerten auf der x-Achse und Pixelanzahl auf der y-Achse.\n",
    "plt.xlim([0, 256])  # Setzt die Grenzen der x-Achse, um sicherzustellen, dass das gesamte Spektrum (0 bis 255) dargestellt wird.\n",
    "plt.show()  # Zeigt das Histogramm im Matplotlib-Fenster an.\n",
    "\n",
    "# Bildfenster schließen\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Kantenerkennung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV-Bibliothek importieren\n",
    "\n",
    "# Webcam starten (0 bedeutet Standard-Webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Schleife, die Frames von der Webcam kontinuierlich liest\n",
    "while True:\n",
    "    ret, frame = cap.read()  # ret gibt an, ob das Frame erfolgreich gelesen wurde, frame enthält das aktuelle Bild\n",
    "    if not ret:  # Wenn kein Frame gelesen werden kann, beende die Schleife\n",
    "        break\n",
    "\n",
    "    # Frame in Graustufen umwandeln\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Canny-Kantenerkennung anwenden (Schwellenwerte: 100 und 200)\n",
    "    edges = cv2.Canny(gray_frame, 100, 200)\n",
    "\n",
    "    # Anzeige des Frames mit erkannten Kanten\n",
    "    cv2.imshow('Edges', edges)\n",
    "    \n",
    "    # Beenden, wenn die Taste 'q' gedrückt wird\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigeben der Webcam-Ressourcen\n",
    "cap.release()\n",
    "\n",
    "# Alle geöffneten OpenCV-Fenster schließen\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "---\n",
    "# **3. Gesichtserkennung**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Code zeigt, wie man mit OpenCV und vortrainierten Haar-Cascade-Modellen in Echtzeit Gesichter von einer Webcam erkennt. Mithilfe des Haar-Cascade-Ansatzes, einem schnellen und effizienten Algorithmus für die Gesichtserkennung, werden die erkannten Gesichter im Videostream hervorgehoben.\n",
    "\n",
    "Der Haar-Cascade-Algorithmus funktioniert, indem er Merkmale wie Kanten und Texturen in mehreren Stufen überprüft. Dadurch erkennt er Gesichter effizient, indem er Regionen im Bild scannt, die diesen Merkmalen entsprechen. Er nutzt vortrainierte Modelle, um Gesichter in Echtzeit aus dem Videostream der Webcam zu detektieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Einfache Gesichtserkennung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Umwandlung in Graustufen (die Haar-Cascade funktioniert besser mit Graustufenbildern)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m gray_frame \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Gesichtserkennung durchführen\u001b[39;00m\n\u001b[0;32m     19\u001b[0m faces \u001b[38;5;241m=\u001b[39m face_cascade\u001b[38;5;241m.\u001b[39mdetectMultiScale(gray_frame, scaleFactor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.1\u001b[39m, minNeighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, minSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m30\u001b[39m))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Haar-Cascade ist ein vortrainierter Klassifikator, der anhand von Merkmalen Gesichter erkennt.\n",
    "# Dieses Modell wurde mit positiven (Gesichter) und negativen (Nicht-Gesichter) Beispielen trainiert, um Gesichtsstrukturen zu erkennen.\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') # Laden des Modells, die XML-Datei enthält die Merkmale die für Gesichtstruktur verwendet werden\n",
    "\n",
    "# Starte den Zugriff auf die Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Lese den aktuellen Frame von der Webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Umwandlung in Graustufen (die Haar-Cascade funktioniert besser mit Graustufenbildern)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Gesichtserkennung durchführen\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    # 'detectMultiScale' ist die Methode zur Gesichtserkennung:\n",
    "    # - scaleFactor: Bestimmt, wie stark das Bild bei jedem Schritt skaliert wird. Ein kleinerer Wert bedeutet genauere Erkennung.\n",
    "    # - minNeighbors: Bestimmt, wie viele Nachbarn jedes Rechteck haben muss, um als Gesicht erkannt zu werden. Höhere Werte ergeben weniger, aber präzisere Gesichtsrechtecke.\n",
    "    # - minSize: Minimale Größe eines erkannten Gesichts, um Fehlmeldungen bei sehr kleinen Objekten zu vermeiden.\n",
    "\n",
    "    # Über alle erkannten Gesichter iterieren und ein Rechteck um jedes Gesicht zeichnen\n",
    "    for (x, y, w, h) in faces: # x, y sind die Koordinaten der oberen linken Ecke, w, h sind Breite und Höhe des Rechtecks\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        # Zeichnet ein Rechteck um jedes erkannte Gesicht, hier in Blau (RGB: 255, 0, 0) und 2 Pixel dick.\n",
    "\n",
    "    # Ergebnis anzeigen\n",
    "    cv2.imshow('Gesichtserkennung', frame)\n",
    "\n",
    "    # Wenn die 'q'-Taste gedrückt wird, beende die Schleife\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigabe der Webcam und Schließen aller Fenster\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### **Anzeigen der Anzahl erkannter Gesichter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Lade das vortrainierte Modell für Gesichtserkennung (Haar-Cascade)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Starte den Zugriff auf die Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Lese den aktuellen Frame von der Webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Umwandlung in Graustufen\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Gesichtserkennung durchführen\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "\n",
    "    # Über alle erkannten Gesichter iterieren und ein Rechteck um jedes Gesicht zeichnen\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Anzahl der erkannten Gesichter auf dem Frame anzeigen\n",
    "    cv2.putText(frame, f'Gesichter erkannt: {len(faces)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Ergebnis anzeigen\n",
    "    cv2.imshow('Gesichtserkennung', frame)\n",
    "\n",
    "    # Wenn die 'q'-Taste gedrückt wird, beende die Schleife\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigabe der Webcam und Schließen aller Fenster\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Gesichtserkennung mit zusätzlicher Augen- und Munderkennung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Lade die vortrainierten Haar-Cascade-Modelle für Gesicht, Augen und Mund\n",
    "# Diese XML-Dateien enthalten die trainierten Modelle für die Erkennung von Gesichtern, Augen und Lächeln\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "\n",
    "# Starte den Zugriff auf die Webcam (0 steht für die Standard-Webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Lese den aktuellen Frame von der Webcam\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Wenn das Frame nicht erfolgreich gelesen wird (ret == False), beende die Schleife\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Umwandlung in Graustufen, da die Haar-Cascade-Klassifikatoren effizienter mit Graustufenbildern arbeiten\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Gesichtserkennung: sucht Gesichter im Graustufenbild\n",
    "    # scaleFactor: Wie stark das Bild bei jedem Schritt skaliert wird, um Gesichter unterschiedlicher Größe zu erkennen\n",
    "    # minNeighbors: Wie viele Nachbarn um ein erkanntes Rechteck liegen müssen, damit es als Gesicht gilt\n",
    "    # minSize: Minimale Größe des Gesichts, um Fehlmeldungen zu vermeiden\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Iteriere über alle erkannten Gesichter\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Zeichne ein Rechteck um jedes erkannte Gesicht (im Originalbild in Blau)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        # Definiere den Gesichtsauschnitt (Region of Interest, ROI) für Augen- und Munderkennung\n",
    "        # Der ROI ist der Bereich im Bild, der das erkannte Gesicht darstellt\n",
    "        roi_gray = gray_frame[y:y+h, x:x+w]  # Graustufenbild des Gesichts\n",
    "        roi_color = frame[y:y+h, x:x+w]  # Farbversion des Gesichts für die Anzeige\n",
    "\n",
    "        # Augen im erkannten Gesicht erkennen\n",
    "        # Es wird nur innerhalb des Gesichts (ROI) nach Augen gesucht\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            # Zeichne ein grünes Rechteck um die erkannten Augen\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "\n",
    "        # Mund (Lächeln) im erkannten Gesicht erkennen\n",
    "        # scaleFactor und minNeighbors werden für den Mund (Lächeln) angepasst, um genaue Ergebnisse zu erzielen\n",
    "        smile = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.7, minNeighbors=22, minSize=(25, 25))\n",
    "        for (sx, sy, sw, sh) in smile:\n",
    "            # Zeichne ein gelbes Rechteck um das erkannte Lächeln\n",
    "            # Beachte, dass das Rechteck nur die untere Hälfte des Mundes abdeckt\n",
    "            cv2.rectangle(roi_color, (sx, sy+int(sh/2)), (sx+sw, sy+sh), (0, 255, 255), 2)\n",
    "\n",
    "    # Ergebnis anzeigen: Das Originalbild mit gezeichneten Rechtecken um Gesichter, Augen und Lächeln\n",
    "    cv2.imshow('Gesicht, Augen und Lächeln', frame)\n",
    "\n",
    "    # Überprüfe, ob die 'q'-Taste gedrückt wird, um die Schleife zu beenden\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigabe der Webcam-Ressourcen und Schließen aller OpenCV-Fenster\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Alters- und Geschlechtsschätzung mit OpenCV und DNN(Deep Neural Network)**\n",
    "Dieser Code demonstriert die Verwendung von OpenCV zur Gesichtserkennung in Echtzeit sowie die Integration von vortrainierten neuronalen Netzen, um Alter und Geschlecht basierend auf den erkannten Gesichtern zu schätzen. Das Caffe-Framework wird verwendet, um die Netzwerke für die Alters- und Geschlechtsschätzung zu laden. Dabei werden die Netzarchitekturen in .prototxt-Dateien definiert, und die gelernten Gewichte werden aus den .caffemodel-Dateien geladen. Im Videostream der Webcam werden die erkannten Gesichter hervorgehoben und die geschätzten Alters- und Geschlechtskategorien über jedem Gesicht angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Lade vortrainierte Modelle für Gesichtserkennung, Alters- und Geschlechtsschätzung\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "age_net = cv2.dnn.readNetFromCaffe(r'Dateien\\Module\\Yolo\\deploy_age.prototxt', r'Dateien\\Module\\Yolo\\age_net.caffemodel')\n",
    "gender_net = cv2.dnn.readNetFromCaffe(r'Dateien\\Module\\Yolo\\deploy_gender.prototxt', r'Dateien\\Module\\Yolo\\gender_net.caffemodel')\n",
    "\n",
    "#.prototxt: Definiert die Architektur eines neuronalen Netzwerks (Schichten, Parameter) im Caffe-Framework.\n",
    "#.caffemodel: Enthält die trainierten Gewichte des Netzwerks, die während des Trainings gelernt wurden.\n",
    "\n",
    "# Alterskategorien\n",
    "age_list = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "# Geschlechtskategorien\n",
    "gender_list = ['Male', 'Female']\n",
    "\n",
    "# Starte den Zugriff auf die Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Umwandlung in Graustufen\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Gesichtserkennung\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Gesicht extrahieren und für DNN vorbereiten\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), (104.0, 177.0, 123.0))\n",
    "\n",
    "        # Geschlechtserkennungq\n",
    "        gender_net.setInput(blob)\n",
    "        gender_preds = gender_net.forward()\n",
    "        gender = gender_list[gender_preds[0].argmax()]\n",
    "\n",
    "        # Alterserkennung\n",
    "        age_net.setInput(blob)\n",
    "        age_preds = age_net.forward()\n",
    "        age = age_list[age_preds[0].argmax()]\n",
    "\n",
    "        # Ergebnisse anzeigen\n",
    "        label = f'{gender}, {age}'\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow('Alters- und Geschlechtsschätzung', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handerkennung in Echtzeit mit OpenCV und Mediapipe**\n",
    "Dieser Code nutzt die Mediapipe-Bibliothek, um in Echtzeit Hände und deren Landmarken (Fingerpositionen und Handgelenke) in einem Videostream von der Webcam zu erkennen. Mithilfe der Mediapipe-Handerkennung werden die erkannten Handpunkte sowie ihre Verbindungen visuell auf dem Bild dargestellt. OpenCV wird verwendet, um die Videoaufnahme zu verarbeiten und die Ergebnisse anzuzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\AddictedSocietyEnv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialisiere Mediapipe Hand-Erkennung\n",
    "mp_hands = mp.solutions.hands  # Mediapipe Hand-Modul laden\n",
    "hands = mp_hands.Hands()  # Handerkennung initialisieren\n",
    "mp_draw = mp.solutions.drawing_utils  # Zeichenwerkzeuge von Mediapipe laden\n",
    "\n",
    "# Webcam oder Video öffnen\n",
    "cap = cv2.VideoCapture(0)  # Webcam starten (0 für Standard-Webcam)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()  # Frame von der Webcam einlesen\n",
    "    if not success:  # Wenn kein Frame gelesen werden kann, beende die Schleife\n",
    "        break\n",
    "    \n",
    "    # Bild in RGB konvertieren, da Mediapipe im RGB-Format arbeitet\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Verarbeite das Bild und erkenne Handlandmarks\n",
    "    result = hands.process(img_rgb)\n",
    "    \n",
    "    # Wenn Handlandmarks erkannt werden\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Zeichne die Handlandmarks und deren Verbindungen auf das Bild\n",
    "            mp_draw.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    # Zeige das Bild mit den erkannten Handlandmarks an\n",
    "    cv2.imshow(\"Hand Detection\", img)\n",
    "    \n",
    "    # Beenden der Schleife, wenn die Taste 'q' gedrückt wird\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigeben der Videoressourcen und Schließen der Fenster\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Echtzeit-Handerkennung mit Abstandsmessung zwischen Daumen und Zeigefinger**\n",
    "Dieser Code verwendet die Mediapipe-Bibliothek, um in Echtzeit Handlandmarken zu erkennen. Er berechnet den euklidischen Abstand zwischen den Spitzen von Daumen und Zeigefinger und zeigt diesen live auf dem Bildschirm an. Zudem werden die Spitzen der Finger und die Verbindung zwischen Daumen und Zeigefinger visuell hervorgehoben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV für Videoaufnahme und Bildverarbeitung importieren\n",
    "import mediapipe as mp  # Mediapipe für Handerkennung importieren\n",
    "import math  # Mathematische Funktionen für die Abstandsmessung\n",
    "\n",
    "# Initialisiere Mediapipe Hand-Erkennung\n",
    "mp_hands = mp.solutions.hands  # Modul für die Handerkennung laden\n",
    "hands = mp_hands.Hands()  # Handerkennungsinstanz erstellen\n",
    "mp_draw = mp.solutions.drawing_utils  # Zeichentools von Mediapipe laden\n",
    "\n",
    "# Webcam oder Video öffnen (0 für Standard-Webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Funktion zur Berechnung des euklidischen Abstands zwischen zwei Punkten\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "# Hauptschleife zur Verarbeitung jedes Frames der Webcam\n",
    "while True:\n",
    "    success, img = cap.read()  # Frame von der Webcam einlesen\n",
    "    if not success:  # Wenn kein Frame gelesen wird, Schleife beenden\n",
    "        break\n",
    "    \n",
    "    # Bild von BGR (OpenCV Standard) nach RGB (Mediapipe Standard) konvertieren\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(img_rgb)  # Mediapipe Handerkennung auf das Bild anwenden\n",
    "    \n",
    "    # Wenn Handlandmarks erkannt wurden\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Handlandmarks und Verbindungen zwischen den Punkten auf das Bild zeichnen\n",
    "            mp_draw.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Extrahiere die Landmarken für Daumen (Landmarke 4) und Zeigefinger (Landmarke 8)\n",
    "            thumb_tip = hand_landmarks.landmark[4]\n",
    "            index_tip = hand_landmarks.landmark[8]\n",
    "\n",
    "            # Berechne die Positionen der Finger im Bild basierend auf den Bilddimensionen\n",
    "            img_height, img_width, _ = img.shape  # Höhe und Breite des Bildes\n",
    "            thumb_x, thumb_y = int(thumb_tip.x * img_width), int(thumb_tip.y * img_height)\n",
    "            index_x, index_y = int(index_tip.x * img_width), int(index_tip.y * img_height)\n",
    "\n",
    "            # Zeichne Kreise an den Spitzen von Daumen und Zeigefinger\n",
    "            cv2.circle(img, (thumb_x, thumb_y), 10, (0, 255, 0), cv2.FILLED)\n",
    "            cv2.circle(img, (index_x, index_y), 10, (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "            # Zeichne eine Linie zwischen den Spitzen von Daumen und Zeigefinger\n",
    "            cv2.line(img, (thumb_x, thumb_y), (index_x, index_y), (255, 0, 0), 3)\n",
    "\n",
    "            # Berechne den Abstand zwischen den beiden Fingern\n",
    "            distance = calculate_distance(thumb_x, thumb_y, index_x, index_y)\n",
    "\n",
    "            # Zeige den berechneten Abstand auf dem Bild an\n",
    "            cv2.putText(img, f'Distance: {int(distance)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Zeige das Bild mit den Handlandmarks und dem Abstand in einem Fenster an\n",
    "    cv2.imshow(\"Hand Detection\", img)\n",
    "\n",
    "    # Beenden der Schleife, wenn die Taste 'q' gedrückt wird\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigeben der Videoressourcen und Schließen der Fenster\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Körperhaltungserkennung und -korrektur mit OpenCV und Mediapipe**\n",
    "Dieser Code verwendet Mediapipe, um die Körperhaltung in Echtzeit zu analysieren. Dabei wird der Winkel zwischen Schulter, Hüfte und Knie berechnet, um eine einfache Bewertung der Haltung vorzunehmen. Wenn der berechnete Winkel auf eine schlechte Haltung hinweist, wird eine Warnung auf dem Bildschirm angezeigt. OpenCV wird verwendet, um die Webcam zu steuern und die Ergebnisse visuell darzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV für die Webcam und Bildverarbeitung\n",
    "import mediapipe as mp  # Mediapipe für Pose-Erkennung\n",
    "import numpy as np  # Numpy für mathematische Berechnungen\n",
    "\n",
    "# MediaPipe Pose initialisieren\n",
    "mp_pose = mp.solutions.pose  # Modul für Pose-Erkennung laden\n",
    "pose = mp_pose.Pose()  # Pose-Erkennungsinstanz erstellen\n",
    "mp_drawing = mp.solutions.drawing_utils  # Zeichenwerkzeuge für Pose Mesh\n",
    "\n",
    "# Webcam öffnen\n",
    "cap = cv2.VideoCapture(0)  # 0 für Standard-Webcam\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\" Berechne den Winkel zwischen drei Punkten \"\"\"\n",
    "    a = np.array(a)  # Punkt A (Schulter)\n",
    "    b = np.array(b)  # Punkt B (Hüfte)\n",
    "    c = np.array(c)  # Punkt C (Knie)\n",
    "    \n",
    "    # Berechnung des Winkels zwischen den Punkten (Schulter, Hüfte, Knie)\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)  # Winkel in Grad umwandeln\n",
    "    \n",
    "    # Sicherstellen, dass der Winkel zwischen 0 und 180 Grad liegt\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Hauptschleife zur Verarbeitung jedes Frames der Webcam\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Frame von der Webcam einlesen\n",
    "    if not ret:  # Wenn kein Frame gelesen wird, Schleife beenden\n",
    "        break\n",
    "\n",
    "    # Konvertiere das Bild von BGR nach RGB (Mediapipe benötigt RGB-Format)\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = pose.process(img_rgb)  # Pose-Erkennung auf das Bild anwenden\n",
    "\n",
    "    # Wenn Pose-Landmarken erkannt wurden\n",
    "    if result.pose_landmarks:\n",
    "        # Zeichne das Pose Mesh (Verbindungen der Körperpunkte) auf das Bild\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, result.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),  # Grün für Punkte\n",
    "            mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2)  # Rot für Verbindungen\n",
    "        )\n",
    "\n",
    "        # Extrahiere die Positionen von Schulter, Hüfte und Knie auf der linken Seite\n",
    "        landmarks = result.pose_landmarks.landmark\n",
    "        shoulder_left = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "        hip_left = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "        knee_left = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "\n",
    "        # Berechne den Winkel zwischen Schulter, Hüfte und Knie (zur Analyse der Körperhaltung)\n",
    "        angle = calculate_angle(shoulder_left, hip_left, knee_left)\n",
    "        \n",
    "        # Zeichne den berechneten Winkel auf das Bild\n",
    "        cv2.putText(frame, str(int(angle)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "        # Zeige eine Warnung an, wenn der Winkel auf eine schlechte Haltung hindeutet\n",
    "        if angle < 160:  # Beispielschwelle für schlechte Haltung (Winkel < 160 Grad)\n",
    "            cv2.putText(frame, 'Bad Posture!', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    # Zeige das Bild mit Pose-Mesh und Haltungsbewertung an\n",
    "    cv2.imshow('Posture Correction', frame)\n",
    "    \n",
    "    # Beenden der Schleife, wenn die Taste 'q' gedrückt wird\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Freigeben der Webcam und Schließen der Fenster\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objekterkennung mit Yolo-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Dateienpfade zu den YOLOv3 Dateien: Konfiguration, Gewichte und Klassenbezeichnungen\n",
    "config_path = r\"Dateien\\Module\\yolov3.cfg\"  # Pfad zur YOLOv3-Konfigurationsdatei\n",
    "weights_path = r\"Dateien\\Module\\yolov3.weights\"  # Pfad zur YOLOv3-Gewichtedatei\n",
    "names_path = r\"Dateien\\Module\\coco.names\"  # Pfad zur Datei mit den Klassenbezeichnungen (z.B. 'Person', 'Auto' etc.)\n",
    "\n",
    "# Laden der Klassenbezeichnungen aus der coco.names Datei\n",
    "with open(names_path, 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]  # Entfernen der Leerzeichen/Zeilenumbrüche und Erstellen einer Liste der Klassennamen\n",
    "\n",
    "# YOLO-Netzwerk laden, wobei die konfigurierten Gewichte und die Netzwerkarchitektur geladen werden\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "# Zugriff auf die Webcam (Index 0 ist normalerweise die Standard-Webcam des Systems)\n",
    "cap = cv2.VideoCapture(0)  # Falls du ein Video nutzen willst, kannst du hier den Dateipfad angeben\n",
    "\n",
    "# Erhalte die Namen aller Netzwerk-Schichten\n",
    "layer_names = net.getLayerNames()\n",
    "\n",
    "# Bestimme die Ausgabeschichten, die von YOLO verwendet werden (dies sind die Schichten, die tatsächlich Vorhersagen machen)\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]\n",
    "\n",
    "# Start der Schleife, die Frames von der Webcam aufnimmt\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Lies einen Frame von der Webcam ein\n",
    "    if not ret:  # Wenn es keine Frames gibt, wird die Schleife beendet\n",
    "        break\n",
    "    \n",
    "    # Bestimme die Höhe, Breite und die Anzahl der Farbkanäle (z.B. RGB)\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Wandelt das Bild in ein Blob-Format um, das für YOLO geeignet ist (skalierte Version des Bildes)\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)  \n",
    "    # 0.00392 ist der Skalierungsfaktor, 416x416 ist die Größe, auf die das Bild skaliert wird\n",
    "\n",
    "    # Übergebe den Blob als Input für das YOLO-Netzwerk\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # Führe eine Vorwärtsausführung im Netzwerk durch, um die Ausgaben aus den Ausgabeschichten zu erhalten\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Initialisierung von Listen, um erkannte Objekte, Vertrauenswerte und Box-Koordinaten zu speichern\n",
    "    class_ids = []  # Speichert die IDs der erkannten Klassen\n",
    "    confidences = []  # Speichert die Vertrauenswerte für jedes erkannte Objekt\n",
    "    boxes = []  # Speichert die Koordinaten der Begrenzungsrahmen der erkannten Objekte\n",
    "\n",
    "    # Schleife über alle erkannten Objekte und deren Informationen\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            # Die ersten 4 Werte beziehen sich auf die Position und Größe des Objekts, die restlichen Werte auf die Wahrscheinlichkeiten\n",
    "            scores = detection[5:]  # Die Klassenscores beginnen ab der fünften Position\n",
    "            class_id = np.argmax(scores)  # Wählt die Klasse mit dem höchsten Wahrscheinlichkeitswert aus\n",
    "            confidence = scores[class_id]  # Holt den Wert der Wahrscheinlichkeit\n",
    "\n",
    "            # Filtert nur Objekte mit einer hohen Erkennungswahrscheinlichkeit heraus (hier über 50%)\n",
    "            if confidence > 0.5:\n",
    "                # Bestimmt die Position und Größe des Begrenzungsrahmens im Bild\n",
    "                center_x = int(detection[0] * width)  # Berechne das Zentrum des Rahmens in X-Richtung\n",
    "                center_y = int(detection[1] * height)  # Berechne das Zentrum des Rahmens in Y-Richtung\n",
    "                w = int(detection[2] * width)  # Breite des Rahmens\n",
    "                h = int(detection[3] * height)  # Höhe des Rahmens\n",
    "\n",
    "                # Berechne die oberen linken Koordinaten des Rahmens\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                # Speichere die Box-Koordinaten, Vertrauenswerte und Klassen-IDs\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Verwende Non-Maximum Suppression, um überlappende Begrenzungsrahmen basierend auf den Wahrscheinlichkeiten zu entfernen\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Zeichne die Ergebnisse auf dem Frame, wenn es erkannte Objekte gibt\n",
    "    if len(indexes) > 0:\n",
    "        for i in indexes.flatten():  # `flatten` wird verwendet, um die 2D-Struktur in eine einfache Liste umzuwandeln\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])  # Hol den Namen der Klasse\n",
    "            confidence = confidences[i]  # Vertrauenswert des erkannten Objekts\n",
    "            color = (0, 255, 0)  # Farbe der Box (grün)\n",
    "            \n",
    "            # Zeichne ein Rechteck um das erkannte Objekt\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            \n",
    "            # Füge einen Text hinzu, der die Klasse und die Erkennungswahrscheinlichkeit zeigt\n",
    "            cv2.putText(frame, f'{label} {confidence:.2f}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    \n",
    "    # Zeige den Frame mit den erkannten Objekten in einem Fenster\n",
    "    cv2.imshow(\"YOLO Object Detection\", frame)\n",
    "\n",
    "    # Beende das Programm, wenn 'q' gedrückt wird\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Schließe die Webcam und zerstöre alle Fenster\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AddictedSocietyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
